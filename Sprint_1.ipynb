{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mZ-Pr0Yp1ws8"
   },
   "source": [
    "# [Problem_1] Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1hl940AN1wtq",
    "outputId": "b70b0eb6-cd0b-4c88-b910-6e633edcb77e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [15541 15542 15543 ... 31078 31079 31080] TEST: [    0     1     2 ... 15538 15539 15540]\n",
      "TRAIN: [    0     1     2 ... 15538 15539 15540] TEST: [15541 15542 15543 ... 31078 31079 31080]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df = pd.read_csv('/application_train.csv')\n",
    "df = df.select_dtypes('number')\n",
    "\n",
    "cleaned_df = df.fillna(0)\n",
    "cleaned_df = cleaned_df[cleaned_df.columns[~cleaned_df.isnull().all()]]\n",
    "\n",
    "y = cleaned_df['TARGET']\n",
    "X = cleaned_df.drop(['TARGET'], axis=1)\n",
    "\n",
    "X = X.to_numpy()\n",
    "kf = KFold(n_splits=2)\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index],X[test_index]\n",
    "    y_train, y_test = y[train_index],y[test_index]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xXB6Q8KD6Ysj"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "UvzAE_-h1wt2"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_trans = scaler.transform(X_train)\n",
    "X_test_trans = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "id": "DAZ2NlPm1wt7",
    "outputId": "609e4a92-1804-4698-b961-777312f42993"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.854898</td>\n",
       "      <td>{'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logic_regression</td>\n",
       "      <td>0.920983</td>\n",
       "      <td>{'C': 1}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model  best_score          best_params\n",
       "0     random_forest    0.854898  {'n_estimators': 5}\n",
       "1  logic_regression    0.920983             {'C': 1}"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model_params = {\n",
    "    'random_forest':{\n",
    "        'model':RandomForestClassifier(),\n",
    "        'params':{\n",
    "            'n_estimators': [1,5,10]\n",
    "        }\n",
    "    },\n",
    "    'logic_regression':{\n",
    "        'model': LogisticRegression(solver=\"liblinear\",multi_class=\"auto\"),\n",
    "        'params': {\n",
    "            'C': [1,5,10]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "scores = []\n",
    "\n",
    "for model_name,mp in model_params.items():\n",
    "    clf = GridSearchCV(mp['model'],mp['params'], return_train_score=False)\n",
    "    clf.fit(X_train_trans,y_train)\n",
    "    scores.append({\n",
    "        'model': model_name,\n",
    "        'best_score': clf.best_score_,\n",
    "        'best_params': clf.best_params_\n",
    "    })\n",
    "best_model_params = pd.DataFrame(scores,columns=['model','best_score','best_params'])\n",
    "best_model_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tDdQw_IQ1wuA"
   },
   "source": [
    "# [Problem 3] Survey from Kaggle Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4IYl3sYX1wuG"
   },
   "source": [
    "1. Hyperparameter Tuning using Grid search\n",
    "2. Gradient Boosting Machine\n",
    "3. Using one type of data\n",
    "4. Early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hdP0_ydf1wuJ"
   },
   "source": [
    "# [Problem 4] Creating a model with high generalization performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C2R-Xb8A1wuL",
    "outputId": "bb3e51e7-06f8-4557-d909-51006d740666"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:430: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/usr/local/lib/python3.7/dist-packages/lightgbm/basic.py:741: UserWarning: silent keyword has been found in `params` and will be ignored.\n",
      "Please use silent argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum validation ROC AUC wasa: 1.00000.\n",
      "The optional number of boosting rounds (estimators) was 1.\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "model = lgb.LGBMClassifier()\n",
    "\n",
    "default_params = model.get_params()\n",
    "\n",
    "N_FOLDS = 5\n",
    "\n",
    "train_set = lgb.Dataset(data = X_train)\n",
    "\n",
    "cv_results = lgb.cv(default_params, train_set, num_boost_round = 10000, early_stopping_rounds = 100, metrics = 'auc', nfold = N_FOLDS, seed = 42)\n",
    "\n",
    "print('The maximum validation ROC AUC wasa: {:.5f}.'.format(cv_results['auc-mean'][-1]))\n",
    "print('The optional number of boosting rounds (estimators) was {}.'.format(len(cv_results['auc-mean'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qMfL0VLd1wuM"
   },
   "source": [
    "# [Problem 5] Final model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "-KFzyRyR1wuN"
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('application_test.csv')\n",
    "\n",
    "test_cleaned_df = test_df.fillna(0)\n",
    "\n",
    "test_X = test_cleaned_df.select_dtypes('number')\n",
    "\n",
    "test_scaler = StandardScaler()\n",
    "test_X_test_trans = scaler.fit_transform(test_X)\n",
    "\n",
    "# est_reg_pred = clf.predict(test_X_test_trans = scaler.fit_transform(test_X)\n",
    "\n",
    "test_reg_pred = clf.predict(test_X_test_trans)\n",
    "\n",
    "kgl_submission = pd.concat([test_df['SK_ID_CURR'], pd.Series(test_reg_pred, name='TARGET')], axis=1)\n",
    "kgl_submission.to_csv('kggl_submission.csv', index=False)\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y8JLb7sm1wuO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Sprint_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
